From 7a442ab63a89231736ab3782f613cfeead73c2ec Mon Sep 17 00:00:00 2001
From: Zhenyu Wang <zhenyuw@linux.intel.com>
Date: Wed, 10 May 2017 17:22:47 +0800
Subject: [PATCH 2/2] POC: Fix gpu mem counting for cgroup based

Should count whole cgroup gpu mem usage instead of just
check one client usage against gpu cgroup limit. This
trys to record whole cgroup gpu mem usage and used to
check with max limit.

Signed-off-by: Zhenyu Wang <zhenyuw@linux.intel.com>
---
 drivers/gpu/drm/drm_file.c      |  1 -
 drivers/gpu/drm/drm_gem.c       | 60 +++++++++++++++++++++--------------------
 drivers/gpu/drm/i915/i915_gem.c |  4 +--
 include/drm/drmP.h              |  2 ++
 include/drm/drm_file.h          |  6 -----
 include/drm/drm_gem.h           |  6 ++---
 include/linux/cgroup_gpu.h      |  2 ++
 kernel/cgroup/gpu.c             | 27 ++++++++++++++++++-
 8 files changed, 66 insertions(+), 42 deletions(-)

diff --git a/drivers/gpu/drm/drm_file.c b/drivers/gpu/drm/drm_file.c
index 73dac9b..3783b65 100644
--- a/drivers/gpu/drm/drm_file.c
+++ b/drivers/gpu/drm/drm_file.c
@@ -222,7 +222,6 @@ static int drm_open_helper(struct file *filp, struct drm_minor *minor)
 	INIT_LIST_HEAD(&priv->pending_event_list);
 	INIT_LIST_HEAD(&priv->event_list);
 	init_waitqueue_head(&priv->event_wait);
-	spin_lock_init(&priv->obj_stat_lock);
 	priv->event_space = 4096; /* set aside 4k for event buffer */
 
 	mutex_init(&priv->event_read_lock);
diff --git a/drivers/gpu/drm/drm_gem.c b/drivers/gpu/drm/drm_gem.c
index 11a207e..9f87bc3 100644
--- a/drivers/gpu/drm/drm_gem.c
+++ b/drivers/gpu/drm/drm_gem.c
@@ -97,6 +97,7 @@ drm_gem_init(struct drm_device *dev)
 
 	mutex_init(&dev->object_name_lock);
 	idr_init(&dev->object_name_idr);
+	spin_lock_init(&dev->object_stat_lock);
 
 	vma_offset_manager = kzalloc(sizeof(*vma_offset_manager), GFP_KERNEL);
 	if (!vma_offset_manager) {
@@ -732,7 +733,7 @@ drm_gem_open_ioctl(struct drm_device *dev, void *data,
 }
 
 /**
- * gem_gem_open - initalizes GEM file-private structures at devnode open time
+ * drm_gem_open - initalizes GEM file-private structures at devnode open time
  * @dev: drm_device which is being opened by userspace
  * @file_private: drm file-private structure to set up
  *
@@ -775,12 +776,8 @@ drm_gem_object_release(struct drm_gem_object *obj)
 {
 	WARN_ON(obj->dma_buf);
 
-	if (obj->filp) {
-		struct drm_file *file_priv = obj->filp->private_data;
-		if (file_priv)
-			drm_gem_obj_del_mem(file_priv, obj->size);
+	if (obj->filp)
 		fput(obj->filp);
-	}
 
 	drm_gem_free_mmap_offset(obj);
 }
@@ -802,6 +799,8 @@ drm_gem_object_free(struct kref *kref)
 		container_of(kref, struct drm_gem_object, refcount);
 	struct drm_device *dev = obj->dev;
 
+	drm_gem_obj_del_mem(dev, current, obj->size);
+
 	if (dev->driver->gem_free_object_unlocked) {
 		dev->driver->gem_free_object_unlocked(obj);
 	} else if (dev->driver->gem_free_object) {
@@ -1009,39 +1008,42 @@ int drm_gem_mmap(struct file *filp, struct vm_area_struct *vma)
 }
 EXPORT_SYMBOL(drm_gem_mmap);
 
-int drm_gem_obj_check_max_mem(struct drm_file *file_priv, u64 size)
+int drm_gem_obj_check_max_mem(struct drm_device *dev,
+			      struct task_struct *task,
+			      u64 size)
 {
-	int ret = 0;
-	struct task_struct *task;
-	
-	spin_lock(&file_priv->obj_stat_lock);
-
-	task = get_pid_task(file_priv->pid, PIDTYPE_PID);
-	if (task) {
-		if (file_priv->obj_mem + size > gpucg_get_max_mem(task)) {
-			ret = 1;
-			DRM_DEBUG_DRIVER("ZHEN: hit max mem %d\n", task->pid);
-		}
-		put_task_struct(task);
-	}
-	spin_unlock(&file_priv->obj_stat_lock);
+	int ret = -1;
+
+	spin_lock(&dev->object_stat_lock);
+	if (gpucg_get_cur_mem(task) + size > gpucg_get_max_mem(task)) {
+		ret = 1;
+		DRM_DEBUG_DRIVER("ZHEN: hit max mem %d\n", task->pid);
+	} else
+		ret = 0;
+	spin_unlock(&dev->object_stat_lock);
 
 	return ret;
 }
 EXPORT_SYMBOL(drm_gem_obj_check_max_mem);
 
-void drm_gem_obj_add_mem(struct drm_file *file_priv, u64 size)
+void drm_gem_obj_add_mem(struct drm_device *dev,
+			 struct task_struct *task,
+			 u64 size)
 {
-	spin_lock(&file_priv->obj_stat_lock);
-	file_priv->obj_mem += size;
-	spin_unlock(&file_priv->obj_stat_lock);
+	spin_lock(&dev->object_stat_lock);
+	printk("zhen: add %u mem %u\n", task_pid_nr(task), size);
+	gpucg_adjust_mem(task, size, true);
+	spin_unlock(&dev->object_stat_lock);
 }
 EXPORT_SYMBOL(drm_gem_obj_add_mem);
 
-void drm_gem_obj_del_mem(struct drm_file *file_priv, u64 size)
+void drm_gem_obj_del_mem(struct drm_device *dev,
+			 struct task_struct *task,
+			 u64 size)
 {
-	spin_lock(&file_priv->obj_stat_lock);
-	file_priv->obj_mem -= size;
-	spin_unlock(&file_priv->obj_stat_lock);
+	spin_lock(&dev->object_stat_lock);
+	printk("zhen: del %u mem %u\n", task_pid_nr(task), size);
+	gpucg_adjust_mem(task, size, false);
+	spin_unlock(&dev->object_stat_lock);
 }
 EXPORT_SYMBOL(drm_gem_obj_del_mem);
diff --git a/drivers/gpu/drm/i915/i915_gem.c b/drivers/gpu/drm/i915/i915_gem.c
index 6566ff5..f0d8fe0 100644
--- a/drivers/gpu/drm/i915/i915_gem.c
+++ b/drivers/gpu/drm/i915/i915_gem.c
@@ -657,7 +657,7 @@ i915_gem_create(struct drm_file *file,
 	if (size == 0)
 		return -EINVAL;
 
-	if (drm_gem_obj_check_max_mem(file, size))
+	if (drm_gem_obj_check_max_mem(&dev_priv->drm, current, size))
 		return -ENOMEM;
 	
 	/* Allocate the new object */
@@ -671,7 +671,7 @@ i915_gem_create(struct drm_file *file,
 	if (ret)
 		return ret;
 
-	drm_gem_obj_add_mem(file, size);
+	drm_gem_obj_add_mem(&dev_priv->drm, current, size);
 	*handle_p = handle;
 	return 0;
 }
diff --git a/include/drm/drmP.h b/include/drm/drmP.h
index e1daa4f..2602ad1 100644
--- a/include/drm/drmP.h
+++ b/include/drm/drmP.h
@@ -461,6 +461,8 @@ struct drm_device {
 	struct drm_vma_offset_manager *vma_offset_manager;
 	/*@} */
 	int switch_power_state;
+
+	spinlock_t object_stat_lock;
 };
 
 /**
diff --git a/include/drm/drm_file.h b/include/drm/drm_file.h
index 3575eed..b400e05 100644
--- a/include/drm/drm_file.h
+++ b/include/drm/drm_file.h
@@ -312,12 +312,6 @@ struct drm_file {
 
 	/* private: */
 	unsigned long lock_count; /* DRI1 legacy lock count */
-
-	/**
-	 * per-client mem accounting
-	 */
-	spinlock_t obj_stat_lock;
-	u64 obj_mem;
 };
 
 /**
diff --git a/include/drm/drm_gem.h b/include/drm/drm_gem.h
index 10ba8b8..224b180 100644
--- a/include/drm/drm_gem.h
+++ b/include/drm/drm_gem.h
@@ -321,9 +321,9 @@ int drm_gem_dumb_destroy(struct drm_file *file,
 			 struct drm_device *dev,
 			 uint32_t handle);
 
-int drm_gem_obj_check_max_mem(struct drm_file *file_priv, u64 size);
-void drm_gem_obj_add_mem(struct drm_file *file_priv, u64 size);
-void drm_gem_obj_del_mem(struct drm_file *file_priv, u64 size);
+int drm_gem_obj_check_max_mem(struct drm_device *dev, struct task_struct *t, u64 size);
+void drm_gem_obj_add_mem(struct drm_device *dev, struct task_struct *t, u64 size);
+void drm_gem_obj_del_mem(struct drm_device *dev, struct task_struct *t, u64 size);
 
 
 #endif /* __DRM_GEM_H__ */
diff --git a/include/linux/cgroup_gpu.h b/include/linux/cgroup_gpu.h
index eb2c2ae..623dbd7 100644
--- a/include/linux/cgroup_gpu.h
+++ b/include/linux/cgroup_gpu.h
@@ -11,5 +11,7 @@
 
 extern s64 gpucg_get_priority(struct task_struct *task);
 extern u64 gpucg_get_max_mem(struct task_struct *task);
+extern u64 gpucg_get_cur_mem(struct task_struct *task);
+extern void gpucg_adjust_mem(struct task_struct *task, u64 size, bool);
 
 #endif
diff --git a/kernel/cgroup/gpu.c b/kernel/cgroup/gpu.c
index 12e77d9..a7763c5 100644
--- a/kernel/cgroup/gpu.c
+++ b/kernel/cgroup/gpu.c
@@ -18,6 +18,7 @@ struct gpu_cgroup {
 	struct cgroup_subsys_state css;
 	s64 prio;
 	u64 max_mem_in_bytes;
+	u64 cur_mem;
 };
 
 static DEFINE_MUTEX(gpucg_mutex);
@@ -90,7 +91,7 @@ static struct cftype gpu_css_files[] = {
 		.write_u64 = gpu_css_set_max_mem,
 		.read_u64 = gpu_css_get_max_mem,
 		.flags = CFTYPE_NOT_ON_ROOT,
-	},
+	}
 };
 
 s64 gpucg_get_priority(struct task_struct *task)
@@ -110,6 +111,29 @@ u64 gpucg_get_max_mem(struct task_struct *task)
 }
 EXPORT_SYMBOL(gpucg_get_max_mem);
 
+u64 gpucg_get_cur_mem(struct task_struct *task)
+{
+	struct gpu_cgroup *cg = get_task_gpucg(task);
+	BUG_ON(!cg);
+	return cg->cur_mem;
+}
+EXPORT_SYMBOL(gpucg_get_cur_mem);
+
+void gpucg_adjust_mem(struct task_struct *task, u64 size, bool add)
+{
+	struct gpu_cgroup *cg = get_task_gpucg(task);
+
+	BUG_ON(!cg);
+
+	mutex_lock(&gpucg_mutex);
+	if (add)
+		cg->cur_mem += size;
+	else
+		cg->cur_mem -= size;
+	mutex_unlock(&gpucg_mutex);
+}
+EXPORT_SYMBOL(gpucg_adjust_mem);
+
 static struct cgroup_subsys_state *
 gpu_css_alloc(struct cgroup_subsys_state *parent_css)
 {
@@ -121,6 +145,7 @@ gpu_css_alloc(struct cgroup_subsys_state *parent_css)
 
 	cg->prio = 0;
 	cg->max_mem_in_bytes = ULONG_MAX;
+
 	return &cg->css;
 }
 
-- 
2.7.4

